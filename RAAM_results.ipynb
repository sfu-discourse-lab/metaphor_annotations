{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3af32a7-e5ae-4103-adeb-6c3ae59c2dbe",
   "metadata": {},
   "source": [
    "# CMT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54b998-82d6-4fd6-b382-22a24a82c767",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8463c3-a059-4fb0-824c-8876fdb0539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8418cfd-ea27-4863-a1b7-0cda2d6c6906",
   "metadata": {},
   "source": [
    "## Reading and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255e23a-1998-4c32-b11d-da0760f2c5fc",
   "metadata": {},
   "source": [
    "### Metaphor Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d6eb62-e848-49d4-b539-5ce5dc937ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in CMT annotation json and save it to a pandas dataframe\n",
    "file_path = 'CMT_July17.json'\n",
    "met_df = pd.read_json(file_path)\n",
    "\n",
    "# extracting labels from the annotations column\n",
    "met_df['labels'] = met_df.apply(lambda row: row.annotations[0]['result'], axis=1)\n",
    "\n",
    "# cleaning up file names \n",
    "met_df['filename'] = met_df.apply(lambda row: re.sub(r\"^[^_]*-\", '', row.file_upload), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f04290f9-009a-42cb-9836-317ca6e881fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary of metaphor labels, where each key is a filename\n",
    "met_labels = {}\n",
    "for name in met_df['filename'].unique():\n",
    "    # creating a new dataframe only containing labels corresponding to one file\n",
    "    new_df = met_df[met_df['filename']==name][['filename', 'labels']].reset_index()\n",
    "    # creating a list to save the labels in \n",
    "    labels_dic = {}\n",
    "    for el in new_df['labels'][0]:\n",
    "        # adding labels to the label list \n",
    "        if el['from_name']=='source':\n",
    "            start = el['value']['start']\n",
    "            end = el['value']['end']\n",
    "            for source in el['value']['taxonomy'][0]:\n",
    "                try: \n",
    "                    labels_dic[source].append([start,end])\n",
    "                except KeyError: \n",
    "                    labels_dic[source] = [[start,end]]\n",
    "    # saving the dic of labels to the dictionary of filenames\n",
    "    met_labels[name] = labels_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcec93-b33f-4687-9f6f-59a967fbaacf",
   "metadata": {},
   "source": [
    "## Corpus Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895a8e13-875a-42a7-b8ab-07d652941469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romha\\AppData\\Local\\Temp\\ipykernel_31836\\1368652667.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analysis['length'] = df_analysis.apply(lambda row: len(tokenizer(row.data['text'])), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# creating a new dataframe based on the metaphor dataframe, with fewer columns\n",
    "df_analysis=met_df[['filename', 'data']]\n",
    "# creating a column that measures the length of the text associated with each filename\n",
    "df_analysis['length'] = df_analysis.apply(lambda row: len(tokenizer(row.data['text'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae7afb2-8ae9-4489-8a32-c8183a9efd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>data</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>china_49.txt</td>\n",
       "      <td>{'text': 'Racist claptrap, MSL.'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>property_73.txt</td>\n",
       "      <td>{'text': 'Smear campaign IMO'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>refugees_22.txt</td>\n",
       "      <td>{'text': 'Don't think so'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>watch_40.txt</td>\n",
       "      <td>{'text': 'Great piece! Thanks.'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>watch_64.txt</td>\n",
       "      <td>{'text': 'Loved this article!'}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                               data  length\n",
       "40      china_49.txt  {'text': 'Racist claptrap, MSL.'}       3\n",
       "70   property_73.txt     {'text': 'Smear campaign IMO'}       3\n",
       "81   refugees_22.txt         {'text': 'Don't think so'}       3\n",
       "132     watch_40.txt   {'text': 'Great piece! Thanks.'}       3\n",
       "141     watch_64.txt    {'text': 'Loved this article!'}       3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortest comments\n",
    "df_analysis.loc[(df_analysis.length == min(df_analysis.length))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b9a17c-e682-4347-93ee-4f2641224a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>data</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>watch_57.txt</td>\n",
       "      <td>{'text': 'Information overload is real. And ve...</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename                                               data  length\n",
       "139  watch_57.txt  {'text': 'Information overload is real. And ve...     441"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest\n",
    "df_analysis.loc[(df_analysis.length == max(df_analysis.length))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03edf44c-5c43-4418-bcbe-f067a7f722f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 150 comments in the corpus. The comments range between 3 and 441 in number of tokens, with an average of 68.39333333333333. The total number of tokens in the corpus is 10259.\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "print('There are {} comments in the corpus. The comments range between {} and {} in number of tokens, with an average of {}. \\\n",
    "The total number of tokens in the corpus is {}.'.format(len(df_analysis), min(df_analysis.length), \n",
    "                                                        max(df_analysis.length), sum(df_analysis.length)/len(df_analysis), \n",
    "                                                        sum(df_analysis.length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc6d07-5c70-49d8-b18f-2089c7f24522",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51057f27-5ddf-47de-9b22-d6bb25acf33b",
   "metadata": {},
   "source": [
    "### Common Source Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3887cb31-1aaf-4d9d-b45e-c2c926d84ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all the potential sources\n",
    "source_list = []\n",
    "for file in met_labels.keys():\n",
    "    source_list.extend(list(met_labels[file]))\n",
    "# creating a dictionary where every potential source is a key and setting the values to zero\n",
    "source_dic = {}\n",
    "for source in set(source_list):\n",
    "    source_dic[source]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17122486-0c15-4475-b15e-be66f6e09dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# populating the dictionary by counting the number of occurences for each source\n",
    "for file in met_labels.keys():\n",
    "    # going through each source in the file's labels \n",
    "    for source in met_labels[file].keys():\n",
    "        # updating the count in the source dictionary\n",
    "        source_dic[source] = source_dic[source] + len(met_labels[file][source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec8437f-ddb3-47ac-b380-968c7f360e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Other', 27),\n",
       " ('Adversary', 23),\n",
       " ('Container(s)', 17),\n",
       " ('Game', 12),\n",
       " ('Transferring an Object', 11),\n",
       " ('Up', 10),\n",
       " ('Journey', 10),\n",
       " ('Control', 9),\n",
       " ('Body', 9),\n",
       " ('War', 9),\n",
       " ('Cover', 8),\n",
       " ('Object(s)', 8),\n",
       " ('Problem', 8),\n",
       " ('Money', 8),\n",
       " ('Location', 8),\n",
       " ('Possession(s)', 8),\n",
       " ('Upward Movement', 7),\n",
       " ('Education', 7),\n",
       " ('Plant', 7),\n",
       " ('Preventing movement/motion', 7),\n",
       " ('Obligations, Duties, Responsibilities', 6),\n",
       " ('Physical Properties', 6),\n",
       " ('Motion/Movement', 6),\n",
       " ('Color', 5),\n",
       " ('Commercial Transaction', 5),\n",
       " ('Moving Object', 5),\n",
       " ('Communication', 5),\n",
       " ('Lacking Possession', 5),\n",
       " ('Machine/Mechanism', 5),\n",
       " ('Motion', 5),\n",
       " ('Comparison', 5),\n",
       " ('Constraint', 4),\n",
       " ('Vision', 4),\n",
       " ('Physical Forces', 4),\n",
       " ('Growth/Rise', 4),\n",
       " ('Time', 4),\n",
       " ('Water', 4),\n",
       " ('Following', 4),\n",
       " ('Down', 4),\n",
       " ('Sound', 4),\n",
       " ('Object', 4),\n",
       " ('Lacking a Needed Possession', 4),\n",
       " ('Forward Movement', 4),\n",
       " ('Adversity', 4),\n",
       " ('Possessing/Having/Possessions', 3),\n",
       " ('Liquid', 3),\n",
       " ('Building', 3),\n",
       " ('Vehicle', 3),\n",
       " ('Brittle Object', 3),\n",
       " ('Visibility', 3),\n",
       " ('Maintaining Position', 3),\n",
       " ('Farm/Domestic Animals', 3),\n",
       " ('Rule Enforcer', 3),\n",
       " ('Cause, Causation, Change', 3),\n",
       " ('Solving a Puzzle', 3),\n",
       " ('Destruction', 3),\n",
       " ('Problem Solving', 3),\n",
       " ('Linked Objects', 3),\n",
       " ('Backward Movement', 2),\n",
       " ('Constructed Object', 2),\n",
       " ('Commodities, Goods, Value', 2),\n",
       " ('1-Or-1 Physical Aggression, Fight', 2),\n",
       " ('Belief(s)', 2),\n",
       " ('Light', 2),\n",
       " ('Properties', 2),\n",
       " ('Vertical Scale', 2),\n",
       " ('Moral(s)/Morality', 2),\n",
       " ('Disposables/Garbage', 2),\n",
       " ('Motion, Change of Location', 2),\n",
       " ('Immoral/Immorality', 2),\n",
       " ('Force', 2),\n",
       " ('Points (Set up in Spatial Configuration)', 2),\n",
       " ('Making Visible', 2),\n",
       " ('Barrier/Obstacle', 2),\n",
       " ('Downward Movement', 2),\n",
       " ('Wealth', 2),\n",
       " ('Story', 2),\n",
       " ('Making', 2),\n",
       " ('Possessor', 2),\n",
       " ('Physical Harm/Injury', 2),\n",
       " ('Movement on a Vertical Scale', 1),\n",
       " ('Stability/Stagnancy', 1),\n",
       " ('Harm', 1),\n",
       " ('Past Events Time', 1),\n",
       " ('Employee', 1),\n",
       " ('Destroyer', 1),\n",
       " ('Burden', 1),\n",
       " ('Body Of Water', 1),\n",
       " ('Region in a Landscape', 1),\n",
       " ('Pointing', 1),\n",
       " ('Cloth, Clothing, Clothes', 1),\n",
       " ('Change, Transformation, Evolution', 1),\n",
       " ('Job/Career', 1),\n",
       " ('Feeling', 1),\n",
       " ('Child', 1),\n",
       " ('Transformation, Evolution', 1),\n",
       " ('An Object', 1),\n",
       " ('Opportunities', 1),\n",
       " ('Physical Closeness', 1),\n",
       " ('Confinement', 1),\n",
       " ('Forceful Extraction', 1),\n",
       " ('Magic', 1),\n",
       " ('Direction', 1),\n",
       " ('Senses (seeing/hearing/touching/etc.)', 1),\n",
       " ('Crime', 1),\n",
       " ('Goal', 1),\n",
       " ('Struggle', 1),\n",
       " ('Disgust', 1),\n",
       " ('Moral/Morality/Goodness', 1),\n",
       " ('Possessing', 1),\n",
       " ('Insanity', 1),\n",
       " ('Animal', 1),\n",
       " ('Violence', 1),\n",
       " ('Attributes', 1),\n",
       " ('Desire (wanting, obtaining, getting)', 1),\n",
       " ('Human Body', 1),\n",
       " ('Colour', 1),\n",
       " ('Treatment/Medicine', 1),\n",
       " ('Strong Emotion', 1),\n",
       " ('Change Of Direction', 1),\n",
       " ('Confinement/Constraint', 1),\n",
       " ('Illness', 1),\n",
       " ('Electrification/Electricity', 1),\n",
       " ('Substance', 1),\n",
       " ('Path', 1),\n",
       " ('Strength', 1),\n",
       " ('Constructed Object, Manufactured Object', 1),\n",
       " ('1-On-1 Physical Aggression, Fight', 1),\n",
       " ('Clothing', 1),\n",
       " ('Cause, Causation', 1),\n",
       " ('Field of Vision', 1),\n",
       " ('Weapons', 1),\n",
       " ('Circular movement', 1),\n",
       " ('Tool', 1),\n",
       " ('Family', 1),\n",
       " ('Importance', 1),\n",
       " ('Babies/Children', 1),\n",
       " ('Logical/Logic', 1),\n",
       " ('Fire', 1),\n",
       " ('Accounting', 1),\n",
       " ('Scales, Linear Scales', 1),\n",
       " ('Locked Container', 1),\n",
       " ('Foreward Movement/Motion', 1),\n",
       " ('Weakness', 1),\n",
       " ('People', 1),\n",
       " ('An External Event Exerting Force On', 1),\n",
       " ('Food', 1),\n",
       " ('Path(s)/Pathway', 1),\n",
       " ('Having A Harmful Possession', 1),\n",
       " ('Kinship', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(source_dic.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5d203-e53a-45c0-bdc1-ff13536404f6",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66de7035-6172-4948-b84c-c9e73b2fde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting and combining all the highlighted metaphor texts\n",
    "text = ''\n",
    "for row in met_df['labels']:\n",
    "    for label in row:\n",
    "        text = text + ' ' + label['value']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9250a249-1a28-4b91-abe5-efec54fe7f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'china': 17, 'start': 8, 'time': 8, 'real': 8, 'us': 8, 'money': 8, 'like': 7, 'point': 6, 'take': 6, 'one': 6, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the words \n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# create a list where all the words are in lowercase\n",
    "words = []\n",
    "for word in tokens:\n",
    "    words.append(word.lower())\n",
    "\n",
    "# create a new list without stop words\n",
    "sw = stopwords.words('english')\n",
    "new_words = []\n",
    "for word in words:\n",
    "    if word not in sw:\n",
    "        new_words.append(word)\n",
    "\n",
    "# create and return the frequency distribution        \n",
    "freqdist = nltk.FreqDist(new_words)\n",
    "freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ff19b-a59f-4c2a-9032-7e88274d1ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
